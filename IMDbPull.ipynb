{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "057a7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "sw = stopwords.words('english')\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a7ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DataSetShare.csv\")\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967a1a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = IMDb()\n",
    "\n",
    "def get_imdb_info(title):\n",
    "    runtime = []\n",
    "    rating = []\n",
    "    count = -1\n",
    "    errors = 0\n",
    "    identifier = []\n",
    "    \n",
    "    for i in title:\n",
    "        count += 1\n",
    "        # Search the first 30 characters on IMDb\n",
    "        result = imdb.search_movie(i[:30])\n",
    "        for i in range(len(result)):\n",
    "            id = result[i].movieID\n",
    "            identifier.append(id)\n",
    "        try:\n",
    "            mov = imdb.get_movie(result[0].movieID, info=['main'])\n",
    "            runtime.append(int(mov.get('runtimes')[0]))\n",
    "            rating.append(mov.get('rating'))\n",
    "        except:\n",
    "            runtime.append('')\n",
    "            rating.append('')\n",
    "            errors += 1\n",
    "            # print(f'Error on index {count}, title: {i}') # Uncomment to investigate which titles were not found\n",
    "    print(f'Total not found: {errors}')\n",
    "    return pd.Series(runtime), pd.Series(rating), pd.Series(identifier)\n",
    "    \n",
    "runtime, rating, identifier = get_imdb_info(df.title)\n",
    "\n",
    "df['runtime'] = runtime\n",
    "df['rating'] = rating\n",
    "df['ID'] = identifier\n",
    "\n",
    "# Replace empty values with NaN\n",
    "df = df.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e6ff84",
   "metadata": {},
   "source": [
    "This csv is what we will use for analytics. It is good to roll!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec13396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"IMDB_ratings.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b75d95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = IMDb()\n",
    "titles = []\n",
    "ids = []\n",
    "# Gets reviews for each stand up routine on IMDB\n",
    "for item in df['ID']:\n",
    "    title = imdb.get_movie_reviews(item)\n",
    "    titles.append(title)\n",
    "    ids.append(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71382045",
   "metadata": {},
   "source": [
    "This new DF is just to house the lists created from above, trying to break down the reviews column into individual reviews instead of a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e96ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdf = pd.DataFrame()\n",
    "content =[]\n",
    "helpful =[]\n",
    "author = []\n",
    "date_list =[]\n",
    "rating = []\n",
    "not_helpful = []\n",
    "titl = []\n",
    "ImID = []\n",
    "\n",
    "for idx, reviews in enumerate(titles):\n",
    "    this_id = ids[idx]\n",
    "    if \"reviews\" not in reviews[\"data\"]:\n",
    "        continue\n",
    "    for review_rec in reviews[\"data\"][\"reviews\"]:\n",
    "        content.append(review_rec[\"content\"])\n",
    "        helpful.append(review_rec[\"helpful\"])\n",
    "        titl.append(review_rec[\"title\"])\n",
    "        author.append(review_rec[\"author\"])\n",
    "        date_list.append(review_rec[\"date\"])\n",
    "        not_helpful.append(review_rec[\"not_helpful\"])\n",
    "        rating.append(review_rec[\"rating\"])\n",
    "        ImID.append(this_id)\n",
    "\n",
    "imdf[\"ID\"] = ImID\n",
    "imdf[\"Reviews\"] = content\n",
    "imdf[\"Helpful\"] = helpful\n",
    "imdf[\"Review_Title\"] = titl\n",
    "imdf[\"Review_Author\"] = author\n",
    "imdf[\"Review_Date\"] = date_list\n",
    "imdf[\"Not_Helpful\"] = not_helpful\n",
    "imdf[\"Rating\"] = rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719bc65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c87104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_tok = []\n",
    "unq_tok = []\n",
    "avg_len = []\n",
    "lex_div = []\n",
    "tten = []\n",
    "words = []\n",
    "transcripts = []\n",
    "for corpus in imdf[\"Reviews\"]:\n",
    "    \n",
    "\n",
    "    total_tokens = 0\n",
    "    unique_tokens = 0\n",
    "    token_len = 0\n",
    "    avg_token_len = 0\n",
    "    lex_diversity = 0\n",
    "\n",
    "    corpus = \"\".join([ch for ch in corpus if ch not in punctuation])\n",
    "    includedTokens = [w for w in corpus.split()]\n",
    "    fold = [w.lower() for w in includedTokens if w.isalpha()]\n",
    "    fold  = [w for w in fold if w not in sw]\n",
    "      \n",
    "# Get the descriptive stats\n",
    "    total_tokens = len(fold)\n",
    "\n",
    "    unique_tokens = len(set(fold))\n",
    "#     if total_tokens == 0:\n",
    "#         break\n",
    "    token_len = [len(w) for w in fold]\n",
    "    avg_token_len = np.mean(token_len)\n",
    "\n",
    "    lex_diversity = len(set(fold))/len(fold)\n",
    "\n",
    "    fdtxt = FreqDist(fold)\n",
    "    fdtxt = fdtxt.most_common(10)\n",
    "\n",
    "    strtext = \"\".join([str(elem)for elem in fdtxt])\n",
    "    top_10 = strtext\n",
    "\n",
    "    tot_tok.append(total_tokens)\n",
    "    unq_tok.append(unique_tokens)\n",
    "    avg_len.append(avg_token_len)\n",
    "    lex_div.append(lex_diversity)\n",
    "    tten.append(top_10)\n",
    "    words.append(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b4ad0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdf[\"Total_Tokens\"] = tot_tok\n",
    "imdf[\"Unique_Tokens\"] = unq_tok\n",
    "imdf[\"Avg_Token_Length\"] = avg_len\n",
    "imdf[\"Lex_Diversity\"] = lex_div\n",
    "imdf[\"Most_Frequent_Words\"] = tten\n",
    "imdf[\"Words\"] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe96622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Review_Author</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Not_Helpful</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Total_Tokens</th>\n",
       "      <th>Unique_Tokens</th>\n",
       "      <th>Avg_Token_Length</th>\n",
       "      <th>Lex_Diversity</th>\n",
       "      <th>Most_Frequent_Words</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6900644</td>\n",
       "      <td>Minhaj's recent turn at the Correspondent's Di...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ur1002035</td>\n",
       "      <td>1 July 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130</td>\n",
       "      <td>108</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>('show', 4)('special', 3)('much', 3)('performa...</td>\n",
       "      <td>[minhajs, recent, turn, correspondents, dinner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6900644</td>\n",
       "      <td>The guy works hard. He has an act close to Chr...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ur18857804</td>\n",
       "      <td>28 July 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>('guy', 1)('works', 1)('hard', 1)('act', 1)('c...</td>\n",
       "      <td>[guy, works, hard, act, close, chris, rock, ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6900644</td>\n",
       "      <td>6/5/18. Minhaj is funny. if you are looking fo...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ur22652704</td>\n",
       "      <td>11 June 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>('minhaj', 2)('funny', 1)('looking', 1)('new',...</td>\n",
       "      <td>[minhaj, funny, looking, new, comedian, laugh,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6900644</td>\n",
       "      <td>1 star might be a bit harsh, but, this had a 9...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ur74642715</td>\n",
       "      <td>23 May 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157</td>\n",
       "      <td>131</td>\n",
       "      <td>5.515924</td>\n",
       "      <td>0.834395</td>\n",
       "      <td>('bad', 4)('life', 4)('peters', 3)('sure', 2)(...</td>\n",
       "      <td>[star, might, bit, harsh, wrote, sure, netflix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6900644</td>\n",
       "      <td>This comedy special really just feels like you...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ur71384678</td>\n",
       "      <td>24 October 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>6.217391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>('comedy', 1)('special', 1)('really', 1)('feel...</td>\n",
       "      <td>[comedy, special, really, feels, like, youre, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>5087554</td>\n",
       "      <td>I agree that dark comedy must not be taken ser...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ur111645782</td>\n",
       "      <td>20 June 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>5.823529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>('agree', 1)('dark', 1)('comedy', 1)('must', 1...</td>\n",
       "      <td>[agree, dark, comedy, must, taken, serious, sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>5087554</td>\n",
       "      <td>I would say the first 40 minutes is an ordinar...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ur24103492</td>\n",
       "      <td>1 August 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>55</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>('even', 3)('minutes', 2)('deep', 2)('always',...</td>\n",
       "      <td>[would, say, first, minutes, ordinary, standup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>5087554</td>\n",
       "      <td>This style of dark, edgy, quick fire jokes com...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ur32900110</td>\n",
       "      <td>3 May 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>('style', 1)('dark', 1)('edgy', 1)('quick', 1)...</td>\n",
       "      <td>[style, dark, edgy, quick, fire, jokes, comedy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>5087554</td>\n",
       "      <td>I did not like this stand up comedy. I had to ...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ur60771994</td>\n",
       "      <td>28 May 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>74</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>('comedy', 4)('jokes', 4)('child', 3)('stand',...</td>\n",
       "      <td>[like, stand, comedy, cut, child, molestation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>5087554</td>\n",
       "      <td>This was one of the funniest yet crudest comed...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ur64080826</td>\n",
       "      <td>30 November 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>81</td>\n",
       "      <td>5.578947</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>('one', 4)('laugh', 3)('show', 3)('audience', ...</td>\n",
       "      <td>[one, funniest, yet, crudest, comedy, shows, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2165 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                            Reviews  Helpful  \\\n",
       "0     6900644  Minhaj's recent turn at the Correspondent's Di...        0   \n",
       "1     6900644  The guy works hard. He has an act close to Chr...        0   \n",
       "2     6900644  6/5/18. Minhaj is funny. if you are looking fo...        0   \n",
       "3     6900644  1 star might be a bit harsh, but, this had a 9...        0   \n",
       "4     6900644  This comedy special really just feels like you...        0   \n",
       "...       ...                                                ...      ...   \n",
       "2160  5087554  I agree that dark comedy must not be taken ser...        0   \n",
       "2161  5087554  I would say the first 40 minutes is an ordinar...        0   \n",
       "2162  5087554  This style of dark, edgy, quick fire jokes com...        0   \n",
       "2163  5087554  I did not like this stand up comedy. I had to ...        0   \n",
       "2164  5087554  This was one of the funniest yet crudest comed...        0   \n",
       "\n",
       "     Review_Title Review_Author       Review_Date  Not_Helpful  Rating  \\\n",
       "0                     ur1002035       1 July 2017            0     NaN   \n",
       "1                    ur18857804      28 July 2017            0     NaN   \n",
       "2                    ur22652704      11 June 2018            0     NaN   \n",
       "3                    ur74642715       23 May 2017            0     NaN   \n",
       "4                    ur71384678   24 October 2019            0     1.0   \n",
       "...           ...           ...               ...          ...     ...   \n",
       "2160                ur111645782      20 June 2021            0     NaN   \n",
       "2161                 ur24103492     1 August 2021            0     NaN   \n",
       "2162                 ur32900110        3 May 2019            0     NaN   \n",
       "2163                 ur60771994       28 May 2018            0     NaN   \n",
       "2164                 ur64080826  30 November 2015            0     NaN   \n",
       "\n",
       "      Total_Tokens  Unique_Tokens  Avg_Token_Length  Lex_Diversity  \\\n",
       "0              130            108          6.300000       0.830769   \n",
       "1               40             40          5.850000       1.000000   \n",
       "2               12             11          5.750000       0.916667   \n",
       "3              157            131          5.515924       0.834395   \n",
       "4               23             23          6.217391       1.000000   \n",
       "...            ...            ...               ...            ...   \n",
       "2160            17             17          5.823529       1.000000   \n",
       "2161            63             55          6.714286       0.873016   \n",
       "2162            16             16          5.500000       1.000000   \n",
       "2163            90             74          5.888889       0.822222   \n",
       "2164            95             81          5.578947       0.852632   \n",
       "\n",
       "                                    Most_Frequent_Words  \\\n",
       "0     ('show', 4)('special', 3)('much', 3)('performa...   \n",
       "1     ('guy', 1)('works', 1)('hard', 1)('act', 1)('c...   \n",
       "2     ('minhaj', 2)('funny', 1)('looking', 1)('new',...   \n",
       "3     ('bad', 4)('life', 4)('peters', 3)('sure', 2)(...   \n",
       "4     ('comedy', 1)('special', 1)('really', 1)('feel...   \n",
       "...                                                 ...   \n",
       "2160  ('agree', 1)('dark', 1)('comedy', 1)('must', 1...   \n",
       "2161  ('even', 3)('minutes', 2)('deep', 2)('always',...   \n",
       "2162  ('style', 1)('dark', 1)('edgy', 1)('quick', 1)...   \n",
       "2163  ('comedy', 4)('jokes', 4)('child', 3)('stand',...   \n",
       "2164  ('one', 4)('laugh', 3)('show', 3)('audience', ...   \n",
       "\n",
       "                                                  Words  \n",
       "0     [minhajs, recent, turn, correspondents, dinner...  \n",
       "1     [guy, works, hard, act, close, chris, rock, ev...  \n",
       "2     [minhaj, funny, looking, new, comedian, laugh,...  \n",
       "3     [star, might, bit, harsh, wrote, sure, netflix...  \n",
       "4     [comedy, special, really, feels, like, youre, ...  \n",
       "...                                                 ...  \n",
       "2160  [agree, dark, comedy, must, taken, serious, sh...  \n",
       "2161  [would, say, first, minutes, ordinary, standup...  \n",
       "2162  [style, dark, edgy, quick, fire, jokes, comedy...  \n",
       "2163  [like, stand, comedy, cut, child, molestation,...  \n",
       "2164  [one, funniest, yet, crudest, comedy, shows, e...  \n",
       "\n",
       "[2165 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59ef4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdf.to_csv(\"IMDB_Review.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
