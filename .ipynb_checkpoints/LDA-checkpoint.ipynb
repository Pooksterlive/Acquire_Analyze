{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from gensim.corpora import Dictionary\n",
    "import numpy as np\n",
    "from gensim.models import LdaMulticore\n",
    "from ast import literal_eval\n",
    "from pprint import pprint\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29423bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Bi-Tri.csv\",converters={\"Words\": literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser \n",
    "\n",
    "# Build bigram and trigram Phrases objects\n",
    "bigram_phrases = Phrases(df.Words[:], min_count=10)\n",
    "trigram_phrases = Phrases(bigram_phrases[df.Words[:]], min_count=5)\n",
    "\n",
    "# Create Phraser model object for faster processing by passing in the Phrases object (Gensim has a confusing API...)\n",
    "bigram_model = Phraser(bigram_phrases)\n",
    "trigram_model = Phraser(trigram_phrases)\n",
    "\n",
    "trigrams = [trigram_model[bigram_model[word]] for word in df.Words]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a5815",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8471198",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "allowed_postags=['NOUN','ADJ','VERB','ADV']\n",
    "lemmatized_words = []\n",
    "for sent in trigrams:\n",
    "    doc = nlp(\" \".join(sent))\n",
    "    lemmatized_words.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lemmatized_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb324ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary(lemmatized_words)\n",
    "id2word.filter_extremes(no_below=10, no_above=0.4)\n",
    "id2word.compactify()\n",
    "corpus = [id2word.doc2bow(word) for word in lemmatized_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 4\n",
    "\n",
    "\n",
    "lda_model = LdaMulticore(corpus=corpus, \n",
    "                             id2word=id2word, \n",
    "                             num_topics=num_topics, \n",
    "                             random_state=1,\n",
    "                             chunksize=30,\n",
    "                             passes=20,\n",
    "                             alpha=0.31,\n",
    "                             eta=0.91,\n",
    "                             eval_every=1,\n",
    "                             per_word_topics=True,\n",
    "                             workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c131e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(lda_model.print_topics(num_words=15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c2b37",
   "metadata": {},
   "source": [
    "Visualizations of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc0507",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim_models.prepare(lda_model, corpus,id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2e37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                         texts=lemmatized_words, \n",
    "                                         dictionary=id2word, \n",
    "                                         coherence='c_v')\n",
    "coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9befe332",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_vecs = []\n",
    "for i in range(len(df.Words)):\n",
    "    top_topics = lda_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(num_topics)]\n",
    "    topic_vecs.append(topic_vec)\n",
    "    \n",
    "topic_vecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_columns = ['Stories', 'Minority_Issues', 'UK', 'Not_Clean']\n",
    "LDA_probs = pd.DataFrame(data=topic_vecs, columns=topic_columns, index=df.index)\n",
    "df = pd.concat([df, LDA_probs], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d6d6c9",
   "metadata": {},
   "source": [
    "Make sure to change the topics list contents as the clusters may change as you run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd1ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "\n",
    "topics = ['Stories', 'Minority_Issues', 'UK', 'Not_Clean']\n",
    "ax = sns.barplot(x=df[topics].mean().index, y=df[topics].mean())\n",
    "ax.set_xticklabels(topics, rotation=40, ha='right')\n",
    "ax.set_title('Mean Topic Probabilities Across The Entire Dataset')\n",
    "ax.set(xlabel='Topics', ylabel='Mean Percentage per Transcript', ylim=(0, .7))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d3e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "X = df[topics]\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "temp_dict = {}\n",
    "inertias = []\n",
    "for n_clusters in range(2,15):\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=1)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "    temp_dict[n_clusters] = [silhouette_avg] \n",
    "    \n",
    "    inertia = clusterer.inertia_\n",
    "    print(\"\\tThe inertia is :\", inertia)\n",
    "    inertias.append(inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('ticks')\n",
    "s_scores = pd.DataFrame(temp_dict).T\n",
    "ax = sns.lineplot(x=s_scores.index, y=s_scores[0], color='teal')\n",
    "# ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "ax.set_xticks(range(2,14))\n",
    "ax.set_ylabel('Silhouette score')\n",
    "ax.set_xlabel('Clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b65e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(range(2,15), inertias, color='teal')\n",
    "ax.set_ylabel('SSE (inertia)')\n",
    "ax.set_xlabel('Clusters')\n",
    "# ax.figure.tight_layout()\n",
    "# ax.figure.savefig('./images/LDAelbow.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = KMeans(n_clusters=4, random_state=10)\n",
    "df['cluster_LDA'] = clusterer.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d784ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Clustered.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster_LDA'] = clusterer.fit_predict(X)\n",
    "\n",
    "for cluster in range(4):\n",
    "    # Create a subplot with 1 row and 1 columns\n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(4, 4)\n",
    "     \n",
    "    ax = sns.barplot(x=df[topics].mean().index, y=df[topics].loc[df.cluster_LDA == cluster].mean())\n",
    "    ax.set_xticklabels(topics, rotation=40, ha='right')   \n",
    "    ax.set_title(f'cluster: {cluster}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7565a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cluster_LDA.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
