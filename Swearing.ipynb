{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea9003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from string import punctuation\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea51086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB_ratings.csv\")\n",
    "\n",
    "#df.Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5108c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words = ['fuck', 'fucking', 'fuckin', 'fucker', 'muthafucka', 'motherfuckers', 'motherfucke', 'motha', 'motherfucker','shit', 'shitter', 'shitting', 'shite', 'bullshit', 'shitty', 'cunt', 'asshole', 'damn', 'goddamn', 'cocksucker', 'bitch', 'ass', 'asshole' ]\n",
    "def get_swear_counts(input_list, swear_list):\n",
    "    swears = 0\n",
    "    for word in swear_list:\n",
    "        if word in input_list:\n",
    "            swears += 1\n",
    "    return swears\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29690cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bad_words'] = df.Words.apply(lambda x: get_swear_counts(x, bad_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7d5f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a6774",
   "metadata": {},
   "source": [
    "We get the swear word counts so we can use that as a clustering tool. In standup comedy, there are clean comics and not-clean comics. This a pre determined cluster before coming into the data, and I want to see how the pre-determined classification of clean or dirty actually stands up in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e72523",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = []\n",
    "trigram = []\n",
    "\n",
    "for row in df[\"Words\"]:\n",
    "    text = re.sub(r'[^\\w\\s]','',row)\n",
    "    bigrm = list(nltk.bigrams(text.split()))\n",
    "    trigrm = list(nltk.ngrams(text.split(),3))\n",
    "    bigram.append(bigrm)\n",
    "    trigram.append(trigrm)\n",
    "\n",
    "df[\"Bigrams\"] = bigram\n",
    "df[\"Trigrams\"] = trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36b644d",
   "metadata": {},
   "source": [
    "Now that we have the bigrams and trigrams we can now start the clustering on it! First we need to write out the dataframe to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068183de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Bi-Tri.csv\",index = False)\n",
    "df.to_pickle(\"Pickle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9f72c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"Total_Tokens\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
